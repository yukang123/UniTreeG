# Specify general configuration
state: 'generation'
device: 'cuda'
num_gpus: 1
eps_ratio: 1e-9 # Will be parsed as string!
base_dir: 'exps'

# Relative path to the train folder (with the model weights etc.) used to load models for generation:
trained_run_folder_dir: './trained/2024-12-23/no_overrides'
predict_on_x1: True

# Specify the sampler specific configurations
sampler:
  noise: 30.0                 # Stochasticity '\eta'
  x1_temp: 1.0                # Temperature for unconditional model
  do_purity_sampling: False   # Should we use purity sampling?
  purity_temp: 1.0            # Temperature for purity sampling (only relevant if do_purity_sampling=True)     
  argmax_final: True          # Should we use argmaxing in the last generation step?
  max_t: 0.98                 # Maximal time point during generation
  dt: 0.001                   # Time step for Euler-method
  sample_zero_time_pads: True # Should we sample SMILES padding at time zero?
  guide_temp: 0.5             # Guidance temperature
  seed: 30                    # Seed to be used to initialize random states of generation
  batch_size: 100 #100             # How many samples to draw in parallel
  max_iterations: 100000      # The maximal number of times the generator is invoked

  guidance_at_x1: False ## guidance at xt

  #### Tunable parameters for the guidance at xt
  sample_k_for_prob_xt_estimation: 30
  low_threshold: 1.0e-8
  gumbel_softmax_t: 1.0

  mcts: True 
  active_set_size: 8
  branch_out_size: 2

  use_guided_rate: False ## use the ungudied rate matrix
  # If use_guidance_rate is True, the below parameters are active
  grad_approx: True    # Use Taylor-approximated guidance (TAG) or not
  use_grad_fn_v1: False
  sample_max: False
  ##############################################
